import torch
import torch.nn as nn
import torch.optim as optim
from torchvision.transforms import ToTensor
from PIL import Image
import numpy as np

# Set the device to Apple M1's GPU
device = torch.device("mps" if torch.backends.mps.is_available() else "cpu")

# Define a simple feed-forward neural network
class SimpleColorNet(nn.Module):
    def __init__(self):
        super(SimpleColorNet, self).__init__()
        self.fc1 = nn.Linear(3, 128)  # Input 3 (RGB), Output 128
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(128, 3)  # Output 3 (RGB)

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))  # Sigmoid to keep output between 0 and 1
        return x

def train_model(model, data, epochs=500):
    optimizer = optim.Adam(model.parameters(), lr=0.005)
    criterion = nn.MSELoss()
    for epoch in range(epochs):
        output = model(data)
        loss = criterion(output, data)  # Directly compare to input colors
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if epoch % 50 == 0:
            print(f'Epoch {epoch + 1}, Loss: {loss.item()}')

# Load the image and prepare data
img = Image.open('/Users/akhilkumar/Desktop/vic_encoding/porsche.png').convert('RGB')
img_tensor = ToTensor()(img).view(-1, 3).to(device)

# Initialize and train the model
model = SimpleColorNet().to(device)
train_model(model, img_tensor)

# Define a fixed palette (example: 16 colors)
palette = torch.tensor([
    [0, 0, 0], [255, 255, 255], [255, 0, 0], [0, 255, 0], [0, 0, 255],
    [255, 255, 0], [0, 255, 255], [255, 0, 255], [192, 192, 192], [128, 128, 128],
    [128, 0, 0], [128, 128, 0], [0, 128, 0], [128, 0, 128], [0, 128, 128], [0, 0, 128]
], dtype=torch.float32) / 255.0  # Normalize the palette
palette = palette.to(device)

# Quantize image
with torch.no_grad():
    predicted_colors = model(img_tensor)
    distances = torch.cdist(predicted_colors, palette)
    closest_colors = distances.argmin(dim=1)
    quantized_colors = palette[closest_colors]

    # Reshape to the original image size
    quantized_img = quantized_colors.view(img.size[1], img.size[0], 3)
    quantized_img = (quantized_img * 255).byte().cpu().numpy()
    result_img = Image.fromarray(quantized_img, 'RGB')
    result_img.save('quantized_image.jpg')
    result_img.show()